{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NTx93LnXRmm"
   },
   "source": [
    "# Object Detection Using Faster RCNN\n",
    "This notebook focuses on improving faster rcnn to get a batter result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oO5Q7PuOW-Gd"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.models.detection.rpn import RPNHead, RegionProposalNetwork\n",
    "from torchvision.models.detection.backbone_utils import mobilenet_backbone\n",
    "import glob\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "import torchvision\n",
    "from torchvision.ops import nms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j0ZBoKIX7jj"
   },
   "source": [
    "We created dataframes for both train and validation datasets in the previous notebook and now we just use those dataframes and the given images to build a model and evaluate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljGh9Hd8YOdS"
   },
   "source": [
    "## Loading and Preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZQm2sNANX1CK"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, bbox, label):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([transforms.ToTensor(),])\n",
    "    image = transform(image)\n",
    "    boxes = torch.tensor([bbox], dtype=torch.float32)\n",
    "    labels = torch.tensor([label], dtype=torch.int64)\n",
    "    target = {}\n",
    "    target[\"boxes\"] = boxes\n",
    "    target[\"labels\"] = labels\n",
    "    return image, target\n",
    "\n",
    "def load_dataset(csv_file, start, end):\n",
    "    df = pd.read_csv(csv_file, names=['directory', 'x1', 'y1', 'x2', 'y2', 'label'])\n",
    "    df = df.iloc[start:end]\n",
    "    df['label'] = [1 for i in range(len(df))]\n",
    "    dataset = []\n",
    "    for index, row in df.iterrows():\n",
    "        image_path = row['directory']\n",
    "        bbox = [row['x1'], row['y1'], row['x2'], row['y2']]\n",
    "        label = row['label']\n",
    "        image, target = preprocess_image(image_path, bbox, label)\n",
    "        dataset.append((image, target))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "oR2TrKZtYU-7"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset('/content/drive/MyDrive/train_annotations.csv', 0, 364)\n",
    "val_dataset = load_dataset('/content/drive/MyDrive/validation_annotations.csv', 0, 152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IrPUtXpKYaWU"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True,\n",
    "                          num_workers=0, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False,\n",
    "                        num_workers=0, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FYAqCJDYbEQ"
   },
   "source": [
    "## Building a Faster RCNN with Custom Settings\n",
    "* ResNet50 as backbone\n",
    "* Custom anchor sizes\n",
    "* Adjusting NMS threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "B4M0DnaLYnly"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "geyXJ6N8ZMQR"
   },
   "outputs": [],
   "source": [
    "anchor_generator = AnchorGenerator(sizes=((32,), (64,), (128,), (256,), (512,)),\n",
    "                                   aspect_ratios=tuple([(0.5, 1.0, 2.0) for _ in range(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ManI9b_cZcPh"
   },
   "outputs": [],
   "source": [
    "rpn_head = RPNHead(256, anchor_generator.num_anchors_per_location()[0])\n",
    "\n",
    "rpn = RegionProposalNetwork(\n",
    "    anchor_generator=anchor_generator,\n",
    "    head=rpn_head,\n",
    "    fg_iou_thresh=0.7,\n",
    "    bg_iou_thresh=0.3,\n",
    "    batch_size_per_image=256,\n",
    "    positive_fraction=0.5,\n",
    "    pre_nms_top_n=dict(training=2000, testing=1000),\n",
    "    post_nms_top_n=dict(training=2000, testing=300),\n",
    "    nms_thresh=0.45  # Custom NMS threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "I1B5QU0cuL1C"
   },
   "outputs": [],
   "source": [
    "model.rpn = rpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LwMrKwLkaCRD"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKnBm1Z-aL8k"
   },
   "source": [
    "Want our model to be more aggressive and reduce false positives so we lower NMS threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LlhdenM8zlh"
   },
   "source": [
    "---\n",
    "Run this cell if model is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufuDAgBc51zX",
    "outputId": "3ed4fba2-e133-45bb-983d-9456b389d8c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/content/faster_rcnn_v3.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JpsS_CI84D6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZV5tjvYSaLbU"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7GhgJLXaqHU"
   },
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "rQYBR2-9alju"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7wfv--na6Dw",
    "outputId": "383cc11b-3f54-4f48-f751-314e39c54abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.018605565652251244\n",
      "Epoch [2/5], Loss: 0.021705161780118942\n",
      "Epoch [3/5], Loss: 0.01977173611521721\n",
      "Epoch [4/5], Loss: 0.011389948427677155\n",
      "Epoch [5/5], Loss: 0.008227230049669743\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {losses.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8_DMJMzZccSG"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'faster_rcnn_v3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koK9ZZ7-8-tz"
   },
   "source": [
    "Validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZhU6khb5IgL",
    "outputId": "6b5c708a-94e3-4cea-c667-39646842491e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.020328189025780086\n"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "num_batches = len(val_loader)\n",
    "model.train()\n",
    "with torch.no_grad():\n",
    "    for images, targets in val_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        val_loss += losses.item()\n",
    "val_loss /= num_batches\n",
    "print(f'Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6zPX_oD-C3m"
   },
   "source": [
    "## Validation Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7Rvcimd-CmJ",
    "outputId": "1ceb5007-4af0-4284-efaa-89ccecd81ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 0.017667774111032486\n",
      "Epoch [2/4], Loss: 0.010981985367834568\n",
      "Epoch [3/4], Loss: 0.00985522661358118\n",
      "Epoch [4/4], Loss: 0.0065686507150530815\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in val_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {losses.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "y1BOr7du_h_m"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'faster_rcnn_v3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xw1NKAJ59Dk8"
   },
   "source": [
    "## Further Analysis: testing new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "CXgkfSrk9ZpZ"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    return image_tensor, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "WEiWJOmTBXfF"
   },
   "outputs": [],
   "source": [
    "def predict_and_save(model, device, image_tensor, image, output_dir, threshold=0.3):\n",
    "    model.eval()\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "    predictions = outputs[0]\n",
    "    boxes = predictions['boxes'].cpu().numpy()\n",
    "    scores = predictions['scores'].cpu().numpy()\n",
    "    filtered_boxes = []\n",
    "    for box, score in zip(boxes, scores):\n",
    "        if score >= threshold:\n",
    "            filtered_boxes.append(box)\n",
    "    for box in filtered_boxes:\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        draw.rectangle(box.tolist(), outline=\"red\")\n",
    "    image_name = os.path.basename(image_path)\n",
    "    output_path = os.path.join(output_dir, image_name)\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "s3YW0nHKBaZQ"
   },
   "outputs": [],
   "source": [
    "image_directory = '/content/drive/MyDrive/Q4/test/'\n",
    "output_directory = '/content/drive/MyDrive/outputs_v3/'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "image_paths = glob.glob(os.path.join(image_directory, '*.jpg'))\n",
    "# Process each image in the directory\n",
    "for image_path in image_paths:\n",
    "    image_tensor, image = preprocess_image(image_path)\n",
    "    predict_and_save(model, device, image_tensor, image, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kS8mtFxWBiRE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
